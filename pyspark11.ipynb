{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPy0CsjZhE8LDbdB3qHNe8v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sumaaithal/PySpark_30Days_Challenge/blob/main/pyspark11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbhmfBwd8ODJ",
        "outputId": "27dd45bb-23c1-41d2-92f0-dad58266735d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (91.189.91.82)] [Connecting to security.ub\u001b[0m\u001b[33m\r0% [Connecting to archive.ubuntu.com (91.189.91.82)] [Connecting to security.ub\u001b[0m\r                                                                               \rHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Connecting to security.ubuntu.com] [Connecting to ppa\u001b[0m\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,298 kB]\n",
            "Get:8 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,031 kB]\n",
            "Get:9 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,547 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [1,538 kB]\n",
            "Hit:13 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:14 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:15 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main Sources [2,246 kB]\n",
            "Get:16 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main amd64 Packages [1,153 kB]\n",
            "Fetched 9,064 kB in 5s (1,666 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "18 packages can be upgraded. Run 'apt list --upgradable' to see them.\n"
          ]
        }
      ],
      "source": [
        "!sudo apt update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\""
      ],
      "metadata": {
        "id": "59csYHzF9BXx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True) # Property used to format output tables better\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "G0xDvaE39BaH",
        "outputId": "ede58cdc-3dca-4888-8563-522b5261972b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x788ee3262440>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://06279da93e40:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = [(\"James\",34), (\"Michael\",56), \\\n",
        "        (\"Robert\",30), (\"Maria\",24) ]\n",
        "\n",
        "df1 = spark.createDataFrame(data = data, schema=[\"name\",\"id\"])\n",
        "df1.printSchema()\n",
        "\n",
        "# Create DataFrame df2 with columns name and id\n",
        "data2=[(34,\"James\"),(45,\"Maria\"), \\\n",
        "       (45,\"Jen\"),(34,\"Jeff\")]\n",
        "\n",
        "df2 = spark.createDataFrame(data = data2, schema = [\"id\",\"name\"])\n",
        "df2.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHdKApWU9Bdv",
        "outputId": "ba64e0b8-69c9-4137-a8c6-075e0a3f973f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- id: long (nullable = true)\n",
            "\n",
            "root\n",
            " |-- id: long (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = df1.unionByName(df2)"
      ],
      "metadata": {
        "id": "4u_jlQub9cm3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-g-pdjqa9cqf",
        "outputId": "88b322cd-5dfe-42fc-cff5-ed7795918cde"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+\n",
            "|   name| id|\n",
            "+-------+---+\n",
            "|  James| 34|\n",
            "|Michael| 56|\n",
            "| Robert| 30|\n",
            "|  Maria| 24|\n",
            "|  James| 34|\n",
            "|  Maria| 45|\n",
            "|    Jen| 45|\n",
            "|   Jeff| 34|\n",
            "+-------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = spark.createDataFrame([[5, 2, 6]], [\"col0\", \"col1\", \"col2\"])\n",
        "df2 = spark.createDataFrame([[6, 7, 3]], [\"col1\", \"col2\", \"col3\"])\n",
        "\n",
        "df3 = df1.unionByName(df2, allowMissingColumns=True)"
      ],
      "metadata": {
        "id": "xoAQodMR9ZLI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "midpJLqj9ZNR",
        "outputId": "18433db1-ece2-4edf-ea9a-0e4240ed91f9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----+----+----+\n",
            "|col0|col1|col2|col3|\n",
            "+----+----+----+----+\n",
            "|   5|   2|   6|null|\n",
            "|null|   6|   7|   3|\n",
            "+----+----+----+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qDN-pc2m9ZQq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}