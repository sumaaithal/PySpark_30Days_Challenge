{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOpyhRd6ZF8ylXQSQWw9wnw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sumaaithal/PySpark_30Days_Challenge/blob/main/pyspark14.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4pcVQnIllJjF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cadc1eec-6681-4735-9f9a-076e916bad73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:6 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "23 packages can be upgraded. Run 'apt list --upgradable' to see them.\n"
          ]
        }
      ],
      "source": [
        "!sudo apt update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.5.0/spark-3.5.0-bin-hadoop3.tgz\n",
        "!tar xf spark-3.5.0-bin-hadoop3.tgz\n",
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.0-bin-hadoop3\""
      ],
      "metadata": {
        "id": "Cf6Oe0JdliHD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True) # Property used to format output tables better\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "UtgzcySkliJh",
        "outputId": "cf92c66c-0dd0-4e67-a297-47bb58fd705c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7888147beb60>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://f5289022a684:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns = [\"Seqno\",\"Name\"]\n",
        "data = [(\"1\", \"john jones\"),\n",
        "    (\"2\", \"tracey smith\"),\n",
        "    (\"3\", \"amy sanders\")]\n",
        "\n",
        "df = spark.createDataFrame(data=data,schema=columns)\n",
        "\n",
        "df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fT4Yy8MlliNA",
        "outputId": "02071343-3fb7-4bea-915e-aba58ff9a6b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------------+\n",
            "|Seqno|Name        |\n",
            "+-----+------------+\n",
            "|1    |john jones  |\n",
            "|2    |tracey smith|\n",
            "|3    |amy sanders |\n",
            "+-----+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import upper,udf\n",
        "from pyspark.sql.types import StringType"
      ],
      "metadata": {
        "id": "dTG5SpgNmy6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.withColumn(\"upperName\", upper(\"Name\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZgsfE07my9U",
        "outputId": "be78a326-5a6c-405a-fff4-0b96675e9c77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------------+------------+\n",
            "|Seqno|        Name|   upperName|\n",
            "+-----+------------+------------+\n",
            "|    1|  john jones|  JOHN JONES|\n",
            "|    2|tracey smith|TRACEY SMITH|\n",
            "|    3| amy sanders| AMY SANDERS|\n",
            "+-----+------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(\"Seqno\",\"Name\", upper(\"Name\").alias(\"UpperName\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZD3zigJtm7QT",
        "outputId": "062aaf54-3ac6-4028-9ea2-1fa498790b3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------------+------------+\n",
            "|Seqno|        Name|   UpperName|\n",
            "+-----+------------+------------+\n",
            "|    1|  john jones|  JOHN JONES|\n",
            "|    2|tracey smith|TRACEY SMITH|\n",
            "|    3| amy sanders| AMY SANDERS|\n",
            "+-----+------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.createOrReplaceTempView(\"TAB\")"
      ],
      "metadata": {
        "id": "E0-bBUVpm7T1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"select Seqno, name, UPPER(Name) as upper_name from TAB\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIEz9qJzmzAA",
        "outputId": "940492fc-a4ab-4d00-942f-3e4be57b4175"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------------+------------+\n",
            "|Seqno|        name|  upper_name|\n",
            "+-----+------------+------------+\n",
            "|    1|  john jones|  JOHN JONES|\n",
            "|    2|tracey smith|TRACEY SMITH|\n",
            "|    3| amy sanders| AMY SANDERS|\n",
            "+-----+------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def uppercase(s):\n",
        "  return s.upper()"
      ],
      "metadata": {
        "id": "dipC9QntmzDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uppercaseUDF = udf(lambda x: uppercase(x), StringType())"
      ],
      "metadata": {
        "id": "x7TFrl8aox6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.withColumn(\"curatedName\", uppercaseUDF(\"Name\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LU24ORfPox9j",
        "outputId": "61f2f8c3-0008-4bb4-e47f-47a11adfc985"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------------+------------+\n",
            "|Seqno|        Name| curatedName|\n",
            "+-----+------------+------------+\n",
            "|    1|  john jones|  JOHN JONES|\n",
            "|    2|tracey smith|TRACEY SMITH|\n",
            "|    3| amy sanders| AMY SANDERS|\n",
            "+-----+------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(\"Seqno\" , \"Name\", uppercaseUDF(\"Name\").alias(\"curated_name\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dx2Y93Zzp2g7",
        "outputId": "8fc87521-9191-4c0e-dcef-d510c59cfc71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------------+------------+\n",
            "|Seqno|        Name|curated_name|\n",
            "+-----+------------+------------+\n",
            "|    1|  john jones|  JOHN JONES|\n",
            "|    2|tracey smith|TRACEY SMITH|\n",
            "|    3| amy sanders| AMY SANDERS|\n",
            "+-----+------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.udf.register(\"uppercaseUDF\",uppercaseUDF)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZBz-6w7p93j",
        "outputId": "821c0484-6d97-4df6-d977-1d0c3f0d225e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function __main__.<lambda>(x)>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"select Seqno, Name, uppercaseUDF(Name) as curated_name from TAB\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcxYK7lup96D",
        "outputId": "6624b370-6a17-40c8-818f-c8f5042a15d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------------+------------+\n",
            "|Seqno|        Name|curated_name|\n",
            "+-----+------------+------------+\n",
            "|    1|  john jones|  JOHN JONES|\n",
            "|    2|tracey smith|TRACEY SMITH|\n",
            "|    3| amy sanders| AMY SANDERS|\n",
            "+-----+------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark[pandas_on_spark]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9U1UBCAYrXiv",
        "outputId": "6095055a-c9e4-4254-ecb2-64e5a0daefe0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark[pandas_on_spark] in /usr/local/lib/python3.10/dist-packages (3.5.0)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark[pandas_on_spark]) (0.10.9.7)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.10/dist-packages (from pyspark[pandas_on_spark]) (1.5.3)\n",
            "Requirement already satisfied: pyarrow>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pyspark[pandas_on_spark]) (10.0.1)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.10/dist-packages (from pyspark[pandas_on_spark]) (1.23.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->pyspark[pandas_on_spark]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->pyspark[pandas_on_spark]) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.0.5->pyspark[pandas_on_spark]) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark.pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUP6VCzQp99h",
        "outputId": "b0a68b51-c576-439e-c357-ec8e4204a15f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/spark-3.5.0-bin-hadoop3/python/pyspark/pandas/__init__.py:50: UserWarning: 'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "technologies = ({\n",
        "    'Fee' :[20000,25000,30000,22000,np.NaN],\n",
        "    'Discount':[1000,2500,1500,1200,3000]\n",
        "               })\n",
        "# Create a DataFrame\n",
        "psdf = pd.DataFrame(technologies)\n",
        "print(psdf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZPZNNKCtDof",
        "outputId": "4c1581ed-bd8f-4a94-d87a-f813ea7b4b32"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Fee  Discount\n",
            "0  20000.0      1000\n",
            "1  25000.0      2500\n",
            "2  30000.0      1500\n",
            "3  22000.0      1200\n",
            "4      NaN      3000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def add(data):\n",
        "  return data[0]+data[1]"
      ],
      "metadata": {
        "id": "ZHlDMFYntDsA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "addDF = psdf.apply(add,axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSXTaHrG1G9m",
        "outputId": "9fd0fe90-c567-408c-d9ab-113727f6645e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/spark-3.5.0-bin-hadoop3/python/pyspark/pandas/utils.py:1016: PandasAPIOnSparkAdviceWarning: If the type hints is not specified for `apply`, it is expensive to infer the data type internally.\n",
            "  warnings.warn(message, PandasAPIOnSparkAdviceWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "addDF"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnoYAVfd1HBM",
        "outputId": "cd38597b-767b-4811-ba2c-34b5f36739c9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    21000.0\n",
              "1    27500.0\n",
              "2    31500.0\n",
              "3    23200.0\n",
              "4        NaN\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}