{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOy7vsu60Gbd96PACMd2WiH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sumaaithal/PySpark_30Days_Challenge/blob/main/pyspark16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcNvCqLE4Y2I",
        "outputId": "21a15cf8-a237-4845-eedd-8a7e03b2e13c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (185.125.190.36)] [Connecting to security.\u001b[0m\u001b[33m\r0% [Connecting to archive.ubuntu.com (185.125.190.36)] [Connecting to security.\u001b[0m\r                                                                               \rGet:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [Connected to ppa.launchpadconte\u001b[0m\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [Connected to ppa.launchpadconte\u001b[0m\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [634 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:10 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [1,572 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,598 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,325 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,304 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,036 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [1,602 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [50.4 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [28.1 kB]\n",
            "Fetched 9,493 kB in 2s (5,623 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "24 packages can be upgraded. Run 'apt list --upgradable' to see them.\n"
          ]
        }
      ],
      "source": [
        "!sudo apt update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.5.0/spark-3.5.0-bin-hadoop3.tgz\n",
        "!tar xf spark-3.5.0-bin-hadoop3.tgz\n",
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.0-bin-hadoop3\""
      ],
      "metadata": {
        "id": "pn35zJoX4m4J"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True) # Property used to format output tables better\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "8YWsiLJ34m92",
        "outputId": "1867b58a-c273-4a48-d87c-cbffe498cc2e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7bfa43a8e800>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://3aff37341a69:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\"Project Gutenberg’s\",\n",
        "        \"Alice’s Adventures in Wonderland\",\n",
        "        \"Project Gutenberg’s\",\n",
        "        \"Adventures in Wonderland\",\n",
        "        \"Project Gutenberg’s\"]\n",
        "\n",
        "rdd = spark.sparkContext.parallelize(data)\n",
        "\n",
        "rdd.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVec6JEV4coe",
        "outputId": "f6c90cd2-a9e4-4623-bc8d-53cdb7dcd584"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Project Gutenberg’s',\n",
              " 'Alice’s Adventures in Wonderland',\n",
              " 'Project Gutenberg’s',\n",
              " 'Adventures in Wonderland',\n",
              " 'Project Gutenberg’s']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd2 = rdd.flatMap(lambda x: x.split(\" \"))\n",
        "\n",
        "for e in rdd2.collect():\n",
        "  print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSPeT1tu4crz",
        "outputId": "dfe26388-ddf5-402c-f720-371a41806333"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Project\n",
            "Gutenberg’s\n",
            "Alice’s\n",
            "Adventures\n",
            "in\n",
            "Wonderland\n",
            "Project\n",
            "Gutenberg’s\n",
            "Adventures\n",
            "in\n",
            "Wonderland\n",
            "Project\n",
            "Gutenberg’s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arrayData = [\n",
        "        ('James',['Java','Scala'],{'hair':'black','eye':'brown'}),\n",
        "        ('Michael',['Spark','Java',None],{'hair':'brown','eye':None}),\n",
        "        ('Robert',['CSharp',''],{'hair':'red','eye':''}),\n",
        "        ('Washington',None,None),\n",
        "        ('Jefferson',['1','2'],{})]"
      ],
      "metadata": {
        "id": "gwM68F1T6QgM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.createDataFrame(data=arrayData, schema=['name','knownLanguages','properties'] )"
      ],
      "metadata": {
        "id": "Ynwalbra6QjU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTsfwH6W6Qlp",
        "outputId": "a218aa87-ad8a-403d-a44c-9266eca40a2d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------------------+--------------------+\n",
            "|      name|     knownLanguages|          properties|\n",
            "+----------+-------------------+--------------------+\n",
            "|     James|      [Java, Scala]|{eye -> brown, ha...|\n",
            "|   Michael|[Spark, Java, NULL]|{eye -> NULL, hai...|\n",
            "|    Robert|         [CSharp, ]|{eye -> , hair ->...|\n",
            "|Washington|               NULL|                NULL|\n",
            "| Jefferson|             [1, 2]|                  {}|\n",
            "+----------+-------------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import explode"
      ],
      "metadata": {
        "id": "ruEGEnsh6QpC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df.select(\"name\", explode(\"knownLanguages\").alias(\"languages\"))"
      ],
      "metadata": {
        "id": "EVTCYqS_6iNv"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYdNX9Bb6iQM",
        "outputId": "2d50472e-5a2a-402c-b184-4f1cdbb72ff8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+\n",
            "|     name|languages|\n",
            "+---------+---------+\n",
            "|    James|     Java|\n",
            "|    James|    Scala|\n",
            "|  Michael|    Spark|\n",
            "|  Michael|     Java|\n",
            "|  Michael|     NULL|\n",
            "|   Robert|   CSharp|\n",
            "|   Robert|         |\n",
            "|Jefferson|        1|\n",
            "|Jefferson|        2|\n",
            "+---------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BF4zj9zJ6iTe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}