{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQDp7zJfKwsXNKVkUnPgmt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sumaaithal/PySpark_30Days_Challenge/blob/main/pyspark13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8smyBMBH_boL",
        "outputId": "e1d58f15-5367-424c-ec3a-ec4cd936d1a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (185.125.190.36)] [1 InRelease 12.7 kB/110\u001b[0m\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:6 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,282 kB]\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [633 kB]\n",
            "Get:8 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,036 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Get:10 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [1,512 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
            "Get:12 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Hit:13 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:14 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [1,572 kB]\n",
            "Get:16 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [28.5 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,304 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,576 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [32.6 kB]\n",
            "Fetched 9,337 kB in 2s (5,948 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "36 packages can be upgraded. Run 'apt list --upgradable' to see them.\n"
          ]
        }
      ],
      "source": [
        "!sudo apt update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\""
      ],
      "metadata": {
        "id": "CRGsFcot_t7I"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True) # Property used to format output tables better\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "Pzp02DfZ_t9s",
        "outputId": "a602769e-7fc4-477d-e670-7afc70c5907a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f2244231fc0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://f5a25bd15765:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "simpleData = ((\"Java\",4000,5), \\\n",
        "    (\"Python\", 4600,10),  \\\n",
        "    (\"Scala\", 4100,15),   \\\n",
        "    (\"Scala\", 4500,15),   \\\n",
        "    (\"PHP\", 3000,20),  \\\n",
        "  )\n",
        "columns= [\"CourseName\", \"fee\", \"discount\"]\n",
        "\n",
        "# Create DataFrame\n",
        "df = spark.createDataFrame(data = simpleData, schema = columns)\n",
        "df.printSchema()\n",
        "df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fobqt3mp_uAr",
        "outputId": "71614d11-a21d-49b3-f72d-c77d56734fba"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- CourseName: string (nullable = true)\n",
            " |-- fee: long (nullable = true)\n",
            " |-- discount: long (nullable = true)\n",
            "\n",
            "+----------+----+--------+\n",
            "|CourseName|fee |discount|\n",
            "+----------+----+--------+\n",
            "|Java      |4000|5       |\n",
            "|Python    |4600|10      |\n",
            "|Scala     |4100|15      |\n",
            "|Scala     |4500|15      |\n",
            "|PHP       |3000|20      |\n",
            "+----------+----+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import upper, transform"
      ],
      "metadata": {
        "id": "8R5zU1Bh_uEr"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_upper_str_columns(df):\n",
        "    return df.withColumn(\"CourseName\",upper(df.CourseName))"
      ],
      "metadata": {
        "id": "gQFz_PA7WEMh"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reduce_price(df):\n",
        "    return df.withColumn(\"new_fee\",df.fee - 1000)"
      ],
      "metadata": {
        "id": "53iVPh1zWEPT"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_discount(df):\n",
        "    return df.withColumn(\"discounted_fee\",  \\\n",
        "             df.new_fee - (df.new_fee * df.discount) / 100)"
      ],
      "metadata": {
        "id": "UMmeM4oaWESl"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df.transform(to_upper_str_columns).transform(reduce_price).transform(apply_discount)"
      ],
      "metadata": {
        "id": "3iFmTRZZWEV-"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        " (\"James,,Smith\",[\"Java\",\"Scala\",\"C++\"],[\"Spark\",\"Java\"]),\n",
        " (\"Michael,Rose,\",[\"Spark\",\"Java\",\"C++\"],[\"Spark\",\"Java\"]),\n",
        " (\"Robert,,Williams\",[\"CSharp\",\"VB\"],[\"Spark\",\"Python\"])\n",
        "]\n",
        "df = spark.createDataFrame(data=data,schema=[\"Name\",\"Languages1\",\"Languages2\"])\n",
        "df.printSchema()\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGbm5_-LX6mZ",
        "outputId": "224a73a0-899f-4af5-dceb-7850a880fe6c"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Languages1: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- Languages2: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            "\n",
            "+----------------+------------------+---------------+\n",
            "|            Name|        Languages1|     Languages2|\n",
            "+----------------+------------------+---------------+\n",
            "|    James,,Smith|[Java, Scala, C++]|  [Spark, Java]|\n",
            "|   Michael,Rose,|[Spark, Java, C++]|  [Spark, Java]|\n",
            "|Robert,,Williams|      [CSharp, VB]|[Spark, Python]|\n",
            "+----------------+------------------+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df.select(transform(\"Languages1\", lambda x: upper(x)).alias(\"languages1\"))"
      ],
      "metadata": {
        "id": "1VQBBcdNjVjq"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90v2L0k4jI9z",
        "outputId": "5d1c6712-1566-49a0-8f04-bb8091233330"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+\n",
            "|languages1        |\n",
            "+------------------+\n",
            "|[JAVA, SCALA, C++]|\n",
            "|[SPARK, JAVA, C++]|\n",
            "|[CSHARP, VB]      |\n",
            "+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1Roq8X0djJBN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}