{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPI4fdQw+EFXVN5zotvYwrO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sumaaithal/PySpark_30Days_Challenge/blob/main/pyspark28.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjO05Cn2YBi2",
        "outputId": "9cbf5629-1871-4652-c69b-3d07e1f45cb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\u001b[33m\r0% [Connecting to security.ubuntu.com (185.125.190.39)] [Connected to cloud.r-p\u001b[0m\r                                                                               \rGet:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [Connecting to ppa.launchpadcont\u001b[0m\r                                                                               \rGet:4 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\u001b[33m\r0% [Waiting for headers] [4 InRelease 0 B/3,626 B 0%] [Connecting to ppa.launch\u001b[0m\u001b[33m\r0% [Waiting for headers] [Connecting to ppa.launchpadcontent.net (185.125.190.8\u001b[0m\r                                                                               \rGet:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease [18.1 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,309 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,617 kB]\n",
            "Get:13 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main Sources [2,263 kB]\n",
            "Get:14 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main amd64 Packages [1,161 kB]\n",
            "Fetched 6,601 kB in 3s (2,223 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "25 packages can be upgraded. Run 'apt list --upgradable' to see them.\n"
          ]
        }
      ],
      "source": [
        "!sudo apt update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.5.0/spark-3.5.0-bin-hadoop3.tgz\n",
        "!tar xf spark-3.5.0-bin-hadoop3.tgz\n",
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.0-bin-hadoop3\""
      ],
      "metadata": {
        "id": "BuS1j9MxYGOl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True) # Property used to format output tables better\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "7iPvcHdrYGRh",
        "outputId": "0a5f5d64-02a6-48c7-8091-5c696f973389"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x798454fba170>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://e68a1d63fbde:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import lit,col, when"
      ],
      "metadata": {
        "id": "MTVPSIBoYwd-"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [(\"111\",50000),(\"222\",60000),(\"333\",40000)]\n",
        "columns= [\"EmpId\",\"Salary\"]\n",
        "df = spark.createDataFrame(data=data,schema=columns)\n",
        "\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qzu4klDvYGUb",
        "outputId": "a850a224-5426-44b2-d9a3-72ecb71409ae"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+\n",
            "|EmpId|Salary|\n",
            "+-----+------+\n",
            "|  111| 50000|\n",
            "|  222| 60000|\n",
            "|  333| 40000|\n",
            "+-----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(col('EmpId'),col('Salary'),\n",
        "          lit(1).alias(\"lit_1\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5LseOIFYchG",
        "outputId": "38d6dfcb-01b6-480e-d5a6-5981fc58ce09"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+-----+\n",
            "|EmpId|Salary|lit_1|\n",
            "+-----+------+-----+\n",
            "|  111| 50000|    1|\n",
            "|  222| 60000|    1|\n",
            "|  333| 40000|    1|\n",
            "+-----+------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df.withColumn(\"lit2\",\n",
        "              when((col(\"Salary\") >= 40000) & (col(\"Salary\")<=50000),lit(100)).otherwise(lit(200)))"
      ],
      "metadata": {
        "id": "h7p_7a-TYclm"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PqRJfRiOYcpL"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oYS2LsFsYGZF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}