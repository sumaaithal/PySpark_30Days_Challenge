{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOXJ2+YQt8wB9qd9o59eqdV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sumaaithal/PySpark_30Days_Challenge/blob/main/pyspark27.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fcYYYFXy5Wj",
        "outputId": "9ab22efe-7241-4b49-f602-bc768f3b5460"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [1 InRelease 0 B/3,626 B 0%] [Co\u001b[0m\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [Connected to ppa.launchpadconte\u001b[0m\r                                                                               \rHit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r                                                                               \rGet:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "\r                                                                               \rHit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,309 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,617 kB]\n",
            "Fetched 3,159 kB in 2s (1,289 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "24 packages can be upgraded. Run 'apt list --upgradable' to see them.\n"
          ]
        }
      ],
      "source": [
        "!sudo apt update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.5.0/spark-3.5.0-bin-hadoop3.tgz\n",
        "!tar xf spark-3.5.0-bin-hadoop3.tgz\n",
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.0-bin-hadoop3\""
      ],
      "metadata": {
        "id": "r4xChq13y-B7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True) # Property used to format output tables better\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "DLAL1RaTy-EZ",
        "outputId": "535d82d8-f767-4428-95ba-224819eb01ef"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7bb1d1342f80>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://d5d1a72154b1:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=[(\"James\",\"Bond\"),(\"Scott\",\"Varsa\")]"
      ],
      "metadata": {
        "id": "BTpzFJHsy-H3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.createDataFrame(data=data,schema=[\"col1\",\"col2\"])"
      ],
      "metadata": {
        "id": "vQoaOzYQzUGt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSOMnsIgzUJF",
        "outputId": "590b64c2-5b28-4a5a-ab4b-1d2e9194bc9d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+\n",
            "| col1| col2|\n",
            "+-----+-----+\n",
            "|James| Bond|\n",
            "|Scott|Varsa|\n",
            "+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import expr"
      ],
      "metadata": {
        "id": "Ip_FO5B00Csx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df.withColumn(\"Name\",\n",
        "              expr(\"col1 || ',' ||col2\"))"
      ],
      "metadata": {
        "id": "HQrF434IzUMg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k44XCAisz0Lj",
        "outputId": "cb360b56-9bde-4b03-8206-e1f666311cd7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+-----------+\n",
            "| col1| col2|       Name|\n",
            "+-----+-----+-----------+\n",
            "|James| Bond| James,Bond|\n",
            "|Scott|Varsa|Scott,Varsa|\n",
            "+-----+-----+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = [(\"James\",\"M\"),(\"Michael\",\"F\"),(\"Jen\",\"\")]\n",
        "columns = [\"name\",\"gender\"]\n",
        "df2 = spark.createDataFrame(data = data, schema = columns)"
      ],
      "metadata": {
        "id": "LCtnMWXpz0OT"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eT0FPsrVz0Q8",
        "outputId": "513665ac-08c4-475d-986c-4bd36f68a5dd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+\n",
            "|   name|gender|\n",
            "+-------+------+\n",
            "|  James|     M|\n",
            "|Michael|     F|\n",
            "|    Jen|      |\n",
            "+-------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = df2.withColumn(\"New_gender\",\n",
        "                     expr(\"CASE WHEN gender = 'M' THEN 'Male' \"+\n",
        "                          \"WHEN gender = 'F' THEN 'Female' \"+\n",
        "                          \"ELSE 'Unknown' END\"))"
      ],
      "metadata": {
        "id": "MTihc9Ewz0UK"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icOuKbrL1T4z",
        "outputId": "5e4412a9-be18-4d96-8bd4-eb20a453d84f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+----------+\n",
            "|   name|gender|New_gender|\n",
            "+-------+------+----------+\n",
            "|  James|     M|      Male|\n",
            "|Michael|     F|    Female|\n",
            "|    Jen|      |   Unknown|\n",
            "+-------+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=[(\"2019-01-23\",1),(\"2019-06-24\",2),(\"2019-09-20\",3)]\n",
        "df4 =spark.createDataFrame(data).toDF(\"date\",\"increment\")"
      ],
      "metadata": {
        "id": "yUslxHwR1T8X"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df4.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ymQEGIO2KXF",
        "outputId": "de143752-d917-4787-9057-a068db6d1572"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---------+\n",
            "|      date|increment|\n",
            "+----------+---------+\n",
            "|2019-01-23|        1|\n",
            "|2019-06-24|        2|\n",
            "|2019-09-20|        3|\n",
            "+----------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df5 = df4.select(df4.date,df4.increment,\n",
        "           expr(\"add_months(date,increment)\").alias(\"date_increment\"))"
      ],
      "metadata": {
        "id": "WtBUNPIu2Sjm"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df5.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6EO5iCa2SmH",
        "outputId": "cb8fe32c-6ef9-4735-dd7d-f1d755c9aa01"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---------+--------------+\n",
            "|      date|increment|date_increment|\n",
            "+----------+---------+--------------+\n",
            "|2019-01-23|        1|    2019-02-23|\n",
            "|2019-06-24|        2|    2019-08-24|\n",
            "|2019-09-20|        3|    2019-12-20|\n",
            "+----------+---------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df6 = df4.select(df4.date,df4.increment,\n",
        "           expr(\"\"\"add_months(date,increment) as date_increment\"\"\"))"
      ],
      "metadata": {
        "id": "hI3UhrQy2Spa"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df6.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWnTLQU52KZr",
        "outputId": "840e4598-9d8b-492e-9455-e9011c3498b4"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---------+--------------+\n",
            "|      date|increment|date_increment|\n",
            "+----------+---------+--------------+\n",
            "|2019-01-23|        1|    2019-02-23|\n",
            "|2019-06-24|        2|    2019-08-24|\n",
            "|2019-09-20|        3|    2019-12-20|\n",
            "+----------+---------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df7 = df4.select(\"increment\",\n",
        "                 expr(\"\"\"cast(increment as string) as str_increment\"\"\"))"
      ],
      "metadata": {
        "id": "WvNDE7CX2Kc9"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df7.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlwnC1TR_Xza",
        "outputId": "c38027c1-ddf8-4577-fd0f-6c0a799bfaa7"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- increment: long (nullable = true)\n",
            " |-- str_increment: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df8 = df4.select(\"date\",\"increment\",\n",
        "                 expr(\"increment+5 as new_increment\"))"
      ],
      "metadata": {
        "id": "pSbTeAfb_X25"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df8.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhMuBk_O_zCu",
        "outputId": "6d4bf65b-79bc-4fbd-b6fe-323afc79647c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---------+-------------+\n",
            "|      date|increment|new_increment|\n",
            "+----------+---------+-------------+\n",
            "|2019-01-23|        1|            6|\n",
            "|2019-06-24|        2|            7|\n",
            "|2019-09-20|        3|            8|\n",
            "+----------+---------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=[(100,2),(200,3000),(500,500)]\n",
        "df9=spark.createDataFrame(data).toDF(\"col1\",\"col2\")"
      ],
      "metadata": {
        "id": "r7U8xtQH_39Z"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df9.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yqg3_8K_4Aw",
        "outputId": "3fb80dea-1f29-4dd9-9d1a-876e2fef3074"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----+\n",
            "|col1|col2|\n",
            "+----+----+\n",
            "| 100|   2|\n",
            "| 200|3000|\n",
            "| 500| 500|\n",
            "+----+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df9.filter(expr(\"col1 == col2\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9T0Nu2y_zGN",
        "outputId": "81ea2d77-1945-481f-9990-3ea25dfe4be8"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----+\n",
            "|col1|col2|\n",
            "+----+----+\n",
            "| 500| 500|\n",
            "+----+----+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}